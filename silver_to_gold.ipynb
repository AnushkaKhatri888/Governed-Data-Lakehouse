{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7616c80b-9f4d-4d6d-8623-d78932d087d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1) Read Silver table\n",
    "silver_df = spark.table(\"catalog_anushka.pdf_fin_silver.pdf_silver\")\n",
    "\n",
    "# 2) Gold transformation\n",
    "gold_df = (\n",
    "    silver_df\n",
    "    # IBAN masking: keep first 4 & last 4, mask the middle\n",
    "    .withColumn(\n",
    "        \"iban_masked\",\n",
    "        F.when(\n",
    "            F.col(\"iban\").isNotNull(),\n",
    "            F.concat(\n",
    "                F.substring(\"iban\", 1, 4),\n",
    "                F.lit(\"XXXXXX\"),\n",
    "                F.substring(\"iban\", -4, 4)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # Direction: debit vs credit\n",
    "    .withColumn(\n",
    "        \"direction\",\n",
    "        F.when(F.col(\"amount\") < 0, F.lit(\"DEBIT\")).otherwise(F.lit(\"CREDIT\"))\n",
    "    )\n",
    "    # Absolute amount for analytics\n",
    "    .withColumn(\"amount_abs\", F.abs(F.col(\"amount\")))\n",
    "    # Simple large transaction flag (tune threshold as needed)\n",
    "    .withColumn(\"is_large_tx\", F.col(\"amount_abs\") > F.lit(1000.0))\n",
    "    # Optional: standardized category names\n",
    "    .withColumn(\n",
    "        \"category_std\",\n",
    "        F.when(F.col(\"category\") == \"LEBENSHALTUNG\", F.lit(\"GROCERIES\"))\n",
    "         .when(F.col(\"category\") == \"FREIZEIT\", F.lit(\"LEISURE\"))\n",
    "         .when(F.col(\"category\") == \"ONLINE\", F.lit(\"ONLINE_SHOPPING\"))\n",
    "         .otherwise(F.col(\"category\"))\n",
    "    )\n",
    "    # Drop raw IBAN from Gold (PII)\n",
    "    .drop(\"iban\")\n",
    ")\n",
    "\n",
    "# 3) Create Gold schema if not exists\n",
    "spark.sql(\"\"\"\n",
    "    CREATE SCHEMA IF NOT EXISTS catalog_anushka.pdf_fin_gold\n",
    "\"\"\")\n",
    "\n",
    "# 4) Write Gold Delta table\n",
    "gold_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"catalog_anushka.pdf_fin_gold.pdf_gold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eef529f-b5f0-471b-b3d2-1aef3fc4b289",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# 1️⃣ EXECUTIVE SUMMARY KPIs (PHYSICAL TABLES)\n",
    "# --------------------------------------------------\n",
    "\n",
    "# ✅ Total Income\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_total_income AS\n",
    "    SELECT \n",
    "        SUM(amount_abs) AS total_income\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "    WHERE direction = 'CREDIT'\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Total Expenses\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_total_expenses AS\n",
    "    SELECT \n",
    "        SUM(amount_abs) AS total_expenses\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "    WHERE direction = 'DEBIT'\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Net Savings / Net Cash Flow\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_net_savings AS\n",
    "    SELECT\n",
    "        SUM(CASE WHEN direction = 'CREDIT' THEN amount_abs ELSE 0 END)\n",
    "      - SUM(CASE WHEN direction = 'DEBIT' THEN amount_abs ELSE 0 END)\n",
    "        AS net_savings\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Savings Rate (%)\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_savings_rate AS\n",
    "    SELECT\n",
    "        ROUND(\n",
    "            (\n",
    "                (\n",
    "                    SUM(CASE WHEN direction = 'CREDIT' THEN amount_abs ELSE 0 END)\n",
    "                  - SUM(CASE WHEN direction = 'DEBIT' THEN amount_abs ELSE 0 END)\n",
    "                )\n",
    "                /\n",
    "                SUM(CASE WHEN direction = 'CREDIT' THEN amount_abs ELSE 0 END)\n",
    "            ) * 100, 2\n",
    "        ) AS savings_rate_percent\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Total Transactions\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_total_transactions AS\n",
    "    SELECT COUNT(*) AS total_transactions\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "\"\"\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2️⃣ TIME SERIES KPIs\n",
    "# --------------------------------------------------\n",
    "\n",
    "# ✅ Daily Income vs Expense\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_daily_income_vs_expense AS\n",
    "    SELECT\n",
    "        booking_date,\n",
    "        SUM(CASE WHEN direction = 'CREDIT' THEN amount_abs ELSE 0 END) AS daily_income,\n",
    "        SUM(CASE WHEN direction = 'DEBIT' THEN amount_abs ELSE 0 END) AS daily_expense\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "    GROUP BY booking_date\n",
    "    ORDER BY booking_date\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Monthly Income vs Expense\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_monthly_income_vs_expense AS\n",
    "    SELECT\n",
    "        DATE_FORMAT(booking_date, 'yyyy-MM') AS month,\n",
    "        SUM(CASE WHEN direction = 'CREDIT' THEN amount_abs ELSE 0 END) AS income,\n",
    "        SUM(CASE WHEN direction = 'DEBIT' THEN amount_abs ELSE 0 END) AS expense\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "    GROUP BY month\n",
    "    ORDER BY month\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Running Balance (Cumulative)\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_running_balance AS\n",
    "    SELECT\n",
    "        booking_date,\n",
    "        SUM(\n",
    "            CASE \n",
    "                WHEN direction = 'CREDIT' THEN amount_abs\n",
    "                ELSE -amount_abs\n",
    "            END\n",
    "        ) OVER (ORDER BY booking_date) AS running_balance\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "    ORDER BY booking_date\n",
    "\"\"\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3️⃣ CATEGORY & MERCHANT KPIs\n",
    "# --------------------------------------------------\n",
    "\n",
    "# ✅ Expense by Category\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_category_expense AS\n",
    "    SELECT\n",
    "        category_std AS category,\n",
    "        SUM(amount_abs) AS total_expense\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "    WHERE direction = 'DEBIT'\n",
    "    GROUP BY category_std\n",
    "    ORDER BY total_expense DESC\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Top 10 Merchants by Spend\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_top_merchants AS\n",
    "    SELECT\n",
    "        description AS merchant,\n",
    "        SUM(amount_abs) AS total_spend\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "    WHERE direction = 'DEBIT'\n",
    "    GROUP BY description\n",
    "    ORDER BY total_spend DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4️⃣ RISK & BEHAVIOR KPIs\n",
    "# --------------------------------------------------\n",
    "\n",
    "# ✅ Burn Rate (Average Daily Expense)\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_burn_rate AS\n",
    "    SELECT\n",
    "        ROUND(AVG(amount_abs), 2) AS avg_daily_burn\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "    WHERE direction = 'DEBIT'\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Large Transaction Count\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE catalog_anushka.pdf_fin_gold.kpi_large_tx_count AS\n",
    "    SELECT COUNT(*) AS large_tx_count\n",
    "    FROM catalog_anushka.pdf_fin_gold.pdf_gold\n",
    "    WHERE is_large_tx = TRUE\n",
    "\"\"\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# ✅ ALL KPI TABLES MATERIALIZED\n",
    "# --------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_to_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}